{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of this project, I used a dataset I found in Kaggle, called \"Fashion-MNIST\" which is a slight\n",
    "# variation to the commonly known MNIST dataset. I decided to use the \"Fashion-MNIST\" dataset just to differ from \n",
    "# the others hehe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import all the need libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import heapq\n",
    "import timeit\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets from the FashionMNIST folder.\n",
    "\n",
    "data_train = pd.read_csv(\"./FashionMNIST/fashion-mnist_train.csv\")\n",
    "data_test = pd.read_csv(\"./FashionMNIST/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Representation of how the dataset looks like.\n",
    "\n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train and test dataframes into features(X) and labels(Y)\n",
    "\n",
    "X_train = data_train.drop([\"label\"],axis=1)\n",
    "Y_train = data_train[[\"label\"]].values.ravel()\n",
    "X_test = data_test.drop([\"label\"],axis=1)\n",
    "Y_test = data_test[[\"label\"]].values.ravel()\n",
    "\n",
    "# I used .ravel() due to some inconsistences with the dataset (..Thanks StackOverflow :D)\n",
    "\n",
    "# Also, since all features range from 0 to 255, we don't need to normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can look at how many rows and columns each dataset has\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create different kind of sizes for training datasets (For testing purposes)\n",
    "\n",
    "def create_dataset(size):\n",
    "    \"\"\"makes a dataset of size \"size\", and returns that datasets images and targets\n",
    "    This is used to make the dataset that will be stored by a model and used in \n",
    "    experimenting with different stored dataset sizes\n",
    "    \"\"\"\n",
    "    small_x_train = X_train[:size]\n",
    "    small_y_train = Y_train[:size]\n",
    "    \n",
    "    return small_x_train, small_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 784), (5000,))"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smaller train set of 1000 rows\n",
    "\n",
    "small_x_train, small_y_train = create_dataset(5000)\n",
    "\n",
    "small_x_train.shape, small_y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the most frequent element in a list\n",
    "\n",
    "def most_frequent(List): \n",
    "    counter = 0\n",
    "    num = List[0] \n",
    "      \n",
    "    for i in List: \n",
    "        curr_frequency = List.count(i) \n",
    "        if(curr_frequency> counter): \n",
    "            counter = curr_frequency \n",
    "            num = i \n",
    "  \n",
    "    return num \n",
    "\n",
    "# Function to calculate the K-NN method accuracy\n",
    "\n",
    "def k_nn(k, x_test, y_test, x_train, y_train, distance_metric):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # Calculate the distance between each image in train set and test set\n",
    "    # I have used cosine similarity, manhattan or euclidean distance\n",
    "    \n",
    "    if(distance_metric == \"cosine\"):\n",
    "        cosine = cosine_similarity(x_test, x_train)\n",
    "        dist = cosine\n",
    "    elif(distance_metric == \"manh\"):\n",
    "        manh = manhattan_distances(x_test, x_train)\n",
    "        dist = manh\n",
    "    elif(distance_metric == \"eucl\"):\n",
    "        eucl = euclidean_distances(x_test, x_train)\n",
    "        dist = eucl\n",
    "    \n",
    "    # Here is use a heap/priority queue to store in an array the indices of the nearest neighbors\n",
    "    # For cosine similarity, I return the indices of the k neighbors with the LARGEST similarity\n",
    "    # For euclidean or manhattan distance, I return the indices of the k neighbors with the SMALLEST distance\n",
    "    \n",
    "    if(distance_metric == \"cosine\"):\n",
    "        knn = [(heapq.nlargest((k), range(len(i)), i.take)) for i in dist]\n",
    "    elif(distance_metric == \"eucl\" or distance_metric == \"manh\"):\n",
    "        knn = [(heapq.nsmallest((k), range(len(i)), i.take)) for i in dist]\n",
    "    \n",
    "    # Here i convert indices to labels\n",
    "    \n",
    "    knn = [[y_train[j] for j in i[:k]] for i in knn]\n",
    "    \n",
    "    # Here we choose the most frequent label as the predicted label for every image of the test set\n",
    "    \n",
    "    pred = [(most_frequent(i)) for i in knn]\n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    # We report the accuracy, f1 score, precision and recall for each of the label classes (0-9)\n",
    "    \n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS AND COMPARISONS:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **3 KNN**\n",
    "- **5.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.77      1000\n",
      "           1       0.98      0.95      0.96      1000\n",
      "           2       0.71      0.72      0.72      1000\n",
      "           3       0.88      0.83      0.85      1000\n",
      "           4       0.72      0.74      0.73      1000\n",
      "           5       0.99      0.71      0.83      1000\n",
      "           6       0.56      0.56      0.56      1000\n",
      "           7       0.80      0.92      0.86      1000\n",
      "           8       0.97      0.91      0.94      1000\n",
      "           9       0.84      0.95      0.89      1000\n",
      "\n",
      "    accuracy                           0.81     10000\n",
      "   macro avg       0.82      0.81      0.81     10000\n",
      "weighted avg       0.82      0.81      0.81     10000\n",
      "\n",
      "Time:  44.390025000000605\n"
     ]
    }
   ],
   "source": [
    "k_nn(3,X_test,Y_test,small_x_train,small_y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **3 KNN**\n",
    "- **60.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81      1000\n",
      "           1       0.98      0.97      0.98      1000\n",
      "           2       0.76      0.79      0.78      1000\n",
      "           3       0.91      0.89      0.90      1000\n",
      "           4       0.80      0.79      0.79      1000\n",
      "           5       1.00      0.82      0.90      1000\n",
      "           6       0.66      0.61      0.64      1000\n",
      "           7       0.88      0.94      0.91      1000\n",
      "           8       0.98      0.96      0.97      1000\n",
      "           9       0.88      0.97      0.92      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Time:  563.1084115999984\n"
     ]
    }
   ],
   "source": [
    "k_nn(3,X_test,Y_test,X_train,Y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **3 KNN**\n",
    "- **60.000 Rows**\n",
    "- **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81      1000\n",
      "           1       0.99      0.99      0.99      1000\n",
      "           2       0.79      0.79      0.79      1000\n",
      "           3       0.92      0.89      0.91      1000\n",
      "           4       0.77      0.85      0.81      1000\n",
      "           5       1.00      0.78      0.87      1000\n",
      "           6       0.72      0.61      0.66      1000\n",
      "           7       0.88      0.94      0.91      1000\n",
      "           8       0.98      0.97      0.98      1000\n",
      "           9       0.85      0.97      0.91      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.87      0.86      0.86     10000\n",
      "weighted avg       0.87      0.86      0.86     10000\n",
      "\n",
      "Time:  895.7321326999954\n"
     ]
    }
   ],
   "source": [
    "k_nn(3,X_test,Y_test,X_train,Y_train,\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **1 KNN**\n",
    "- **5.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.75      1000\n",
      "           1       0.97      0.95      0.96      1000\n",
      "           2       0.70      0.71      0.70      1000\n",
      "           3       0.86      0.80      0.83      1000\n",
      "           4       0.70      0.71      0.71      1000\n",
      "           5       0.98      0.73      0.84      1000\n",
      "           6       0.53      0.55      0.54      1000\n",
      "           7       0.82      0.91      0.86      1000\n",
      "           8       0.97      0.92      0.95      1000\n",
      "           9       0.84      0.95      0.89      1000\n",
      "\n",
      "    accuracy                           0.80     10000\n",
      "   macro avg       0.81      0.80      0.80     10000\n",
      "weighted avg       0.81      0.80      0.80     10000\n",
      "\n",
      "Time:  39.031778899996425\n"
     ]
    }
   ],
   "source": [
    "k_nn(1,X_test,Y_test,small_x_train,small_y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **1 KNN**\n",
    "- **60.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      1000\n",
      "           1       0.98      0.98      0.98      1000\n",
      "           2       0.75      0.77      0.76      1000\n",
      "           3       0.89      0.88      0.88      1000\n",
      "           4       0.78      0.76      0.77      1000\n",
      "           5       0.99      0.86      0.92      1000\n",
      "           6       0.64      0.62      0.63      1000\n",
      "           7       0.90      0.95      0.93      1000\n",
      "           8       0.98      0.95      0.97      1000\n",
      "           9       0.90      0.97      0.94      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Time:  525.5209583999967\n"
     ]
    }
   ],
   "source": [
    "k_nn(1,X_test,Y_test,X_train,Y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **1 KNN**\n",
    "- **60.000 Rows**\n",
    "- **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.80      1000\n",
      "           1       0.98      0.99      0.98      1000\n",
      "           2       0.77      0.79      0.78      1000\n",
      "           3       0.92      0.89      0.91      1000\n",
      "           4       0.77      0.81      0.79      1000\n",
      "           5       0.99      0.82      0.90      1000\n",
      "           6       0.70      0.62      0.65      1000\n",
      "           7       0.90      0.94      0.92      1000\n",
      "           8       0.98      0.97      0.97      1000\n",
      "           9       0.86      0.97      0.91      1000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Time:  828.915626099988\n"
     ]
    }
   ],
   "source": [
    "k_nn(1,X_test,Y_test,X_train,Y_train,\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Class Centroid Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the NCC method accuracy\n",
    "\n",
    "def NCC(classes, x_test, y_test, x_train, y_train, distance_metric):\n",
    "    \n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    # Array of 9 classes x 784 feature vectors \n",
    "    centers= np.zeros((classes,x_train.shape[1]))\n",
    "    \n",
    "    # Array of how many images in each class\n",
    "    centersNo= [0 for i in range(10)]\n",
    "\n",
    "    # Calculate the class centroids \n",
    "    \n",
    "    for i in range(x_train.shape[0]):\n",
    "        centers[y_train[i]]+=x_train.iloc[i]\n",
    "        centersNo[y_train[i]]+=1\n",
    "        \n",
    "    for i in range(classes):\n",
    "        centers[i]/=centersNo[i]\n",
    "        \n",
    "     \n",
    "    # Down below, the code is almost identical to the knn above, but instead of the training set we have the class centroids\n",
    "    # and we only need the 1st \"nearest neighbor\", thus the 1st closest class centroid\n",
    "    # Calculate the distance between each image in train set and test set\n",
    "    # I have used cosine similarity, manhattan or euclidean distance\n",
    "    \n",
    "    if(distance_metric == \"cosine\"):\n",
    "        cosine = cosine_similarity(x_test, centers)\n",
    "        dist = cosine\n",
    "    elif(distance_metric == \"manh\"):\n",
    "        manh = manhattan_distances(x_test, centers)\n",
    "        dist = manh\n",
    "    elif(distance_metric == \"eucl\"):\n",
    "        eucl = euclidean_distances(x_test, centers)\n",
    "        dist = eucl\n",
    "        \n",
    "    \n",
    "    # Here is use a heap/priority queue to store in an array the index of the nearest centroid\n",
    "    # For cosine similarity, I return the indx of the centroid with the LARGEST similarity\n",
    "    # For euclidean or manhattan distance, I return the indices of the k neighbors with the SMALLEST distance\n",
    "    \n",
    "    if(distance_metric == \"cosine\"):\n",
    "        knn = [(heapq.nlargest((1), range(len(i)), i.take)) for i in dist]\n",
    "    elif(distance_metric == \"eucl\" or distance_metric == \"manh\"):\n",
    "        knn = [(heapq.nsmallest((1), range(len(i)), i.take)) for i in dist]\n",
    "    \n",
    "    \n",
    "    # Here we choose the most frequent label as the predicted label for every image of the test set\n",
    "    \n",
    "    pred = [i for i in knn]\n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    # We report the accuracy, f1 score, precision and recall for each of the label classes (0-9)\n",
    "    \n",
    "    print(classification_report(y_test, pred))\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    print('Time: ', stop - start)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **5.000 Rows**\n",
    "- **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74      1000\n",
      "           1       0.97      0.91      0.94      1000\n",
      "           2       0.57      0.64      0.60      1000\n",
      "           3       0.69      0.88      0.77      1000\n",
      "           4       0.52      0.51      0.51      1000\n",
      "           5       0.54      0.29      0.38      1000\n",
      "           6       0.39      0.26      0.31      1000\n",
      "           7       0.67      0.81      0.73      1000\n",
      "           8       0.92      0.83      0.87      1000\n",
      "           9       0.67      0.84      0.75      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.66      0.68      0.66     10000\n",
      "weighted avg       0.66      0.68      0.66     10000\n",
      "\n",
      "Time:  8.229619499994442\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,small_x_train,small_y_train,\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **5.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      1000\n",
      "           1       0.97      0.90      0.93      1000\n",
      "           2       0.60      0.50      0.55      1000\n",
      "           3       0.71      0.81      0.76      1000\n",
      "           4       0.54      0.61      0.57      1000\n",
      "           5       0.49      0.76      0.60      1000\n",
      "           6       0.37      0.20      0.26      1000\n",
      "           7       0.74      0.78      0.76      1000\n",
      "           8       0.94      0.76      0.84      1000\n",
      "           9       0.84      0.86      0.85      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.68     10000\n",
      "weighted avg       0.69      0.69      0.68     10000\n",
      "\n",
      "Time:  1.4389641000016127\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,small_x_train,small_y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **5.000 Rows**\n",
    "- **Manhattan Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69      1000\n",
      "           1       0.76      0.95      0.84      1000\n",
      "           2       0.64      0.26      0.37      1000\n",
      "           3       0.56      0.68      0.61      1000\n",
      "           4       0.43      0.66      0.52      1000\n",
      "           5       0.43      0.55      0.48      1000\n",
      "           6       0.38      0.17      0.23      1000\n",
      "           7       0.58      0.88      0.70      1000\n",
      "           8       0.96      0.55      0.70      1000\n",
      "           9       0.84      0.79      0.82      1000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.63      0.61      0.60     10000\n",
      "weighted avg       0.63      0.61      0.60     10000\n",
      "\n",
      "Time:  1.4846222000051057\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,small_x_train,small_y_train,\"manh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **60.000 Rows**\n",
    "- **Cosine Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73      1000\n",
      "           1       0.97      0.91      0.94      1000\n",
      "           2       0.57      0.66      0.61      1000\n",
      "           3       0.69      0.88      0.77      1000\n",
      "           4       0.53      0.52      0.52      1000\n",
      "           5       0.56      0.28      0.37      1000\n",
      "           6       0.40      0.25      0.31      1000\n",
      "           7       0.65      0.83      0.73      1000\n",
      "           8       0.92      0.85      0.88      1000\n",
      "           9       0.68      0.84      0.75      1000\n",
      "\n",
      "    accuracy                           0.68     10000\n",
      "   macro avg       0.67      0.68      0.66     10000\n",
      "weighted avg       0.67      0.68      0.66     10000\n",
      "\n",
      "Time:  310.6555013999896\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,X_train,Y_train,\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **60.000 Rows**\n",
    "- **Euclidean Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70      1000\n",
      "           1       0.96      0.90      0.92      1000\n",
      "           2       0.59      0.50      0.54      1000\n",
      "           3       0.71      0.80      0.75      1000\n",
      "           4       0.55      0.60      0.57      1000\n",
      "           5       0.48      0.76      0.59      1000\n",
      "           6       0.37      0.20      0.26      1000\n",
      "           7       0.74      0.79      0.76      1000\n",
      "           8       0.93      0.76      0.84      1000\n",
      "           9       0.85      0.85      0.85      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.69      0.69      0.68     10000\n",
      "weighted avg       0.69      0.69      0.68     10000\n",
      "\n",
      "Time:  14.73205340000277\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,X_train,Y_train,\"eucl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **60.000 Rows**\n",
    "- **Manhattan Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69      1000\n",
      "           1       0.76      0.94      0.84      1000\n",
      "           2       0.64      0.25      0.36      1000\n",
      "           3       0.56      0.69      0.61      1000\n",
      "           4       0.43      0.66      0.52      1000\n",
      "           5       0.42      0.53      0.47      1000\n",
      "           6       0.37      0.17      0.23      1000\n",
      "           7       0.57      0.89      0.69      1000\n",
      "           8       0.96      0.55      0.70      1000\n",
      "           9       0.85      0.79      0.82      1000\n",
      "\n",
      "    accuracy                           0.61     10000\n",
      "   macro avg       0.63      0.61      0.59     10000\n",
      "weighted avg       0.63      0.61      0.59     10000\n",
      "\n",
      "Time:  15.737960799990105\n"
     ]
    }
   ],
   "source": [
    "NCC(10,X_test,Y_test,X_train,Y_train,\"manh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "---\n",
    "Based on the experiments above, for a 10.000 rows test set:\n",
    "\n",
    "***The most accurate kNN algorithm (86% accuracy)*** uses:\n",
    "\n",
    "- **3 KNN**\n",
    "- **The whole Training Set**\n",
    "- **Euclidean Distance**\n",
    "\n",
    "With almost ***9 minutes*** of training and predicting time\n",
    "\n",
    "***The most accurate NCC algorithm (69% accuracy)*** uses:\n",
    "\n",
    "- **The whole Training Set OR 5000 rows on Training Set**\n",
    "- **Euclidean Distance**\n",
    "\n",
    "With almost ***15 seconds*** for the whole Training Set and ***1.5 second*** for only 5000 rows on Training Set.\n",
    "\n",
    "## So, between kNN and NCC, we have:\n",
    "---\n",
    "***Most Accurate:*** ***kNN (86%)*** vs NCC (69%)\n",
    "\n",
    "***Fastest (60.000 rows):*** kNN (9 minutes) vs ***NCC (15 seconds)***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
