## Neural Networks Project
### The purpose of this project was to get used to the mechanisms and logic behind neural networks, support vector machines and kernel functions. 

I used the **sklearn** library to run some algorithms, while few others I implemented myself from scratch.

I experimented using a Multilayer Perceptron (MLP), a Support Vector Machine (SVM), and a Radial Basis Function Neural Network (RBFNN).

I also implemented the k-Nearest-Neighbors (k-NN) algorithm along with the Nearest Class Centroid (NCC) algorithm, to serve as baseline accuracy and speed benchmarks when testing my machine learning algorithms. 

In my presentation, I introduce my dataset ([Fashion-MNIST](https://www.kaggle.com/zalando-research/fashionmnist)), the logic, results and visualizations behind my various experiments.

Things I experimented with:

***Multilayer Perceptron:***
- Number of hidden layers
- Number of neurons in each layer
- Activation functions
- Batch sizes
- Learning rates
- Data shuffling

***Support Vector Machine:***
- Kernels
- C parameter
- γ parameter
- Polynomial kernel degree
- Normalization
- Principal Component Analysis (PCA)

***Radial Basis Function Neural Network:***
- Number of hidden neurons
- K-means / Random centroids
- β coefficient


